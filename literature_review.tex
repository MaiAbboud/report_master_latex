\chapter{دراسة نظرية ومرجعية}
\section{مقدمة}
يعرض هذا الفصل مقدمة عن مفهوم الملاحقة وعن أنواعها، بالإضافة إلى دراسة مرجعية بأنواع خوارزميات الملاحقة فيما يخص التعلم العميق، ثم ننتقل إلى شرح نموذج المحول كونه الكتلة الأساسية في خوارزمية الملاحقة 
\textLR{SwinTrack\cite{swinTrack}},
بحيث نبدأ بشرح عام عن النماذج السابقة له، وكيفية تطور بنيته، ونعرض بالتفصيل تابع الانتباه وهو التابع المستخدم في عملية دمج السمات في نموذجنا المقترح.
ومن ثم نستعرض تطبيقات المحول في الرؤية الصنعية مثل الكشف والتصنيف ونركز على تطبيقاته في الملاحقة, وأخيراً نتحدث بالتفصيل عن محول 
\textLR{Swin}
كونه النموذج المعتمد في استخلاص السمات.
\input{definition of tracking.tex}
\input{types of trackers.tex}
\input{types of DL trackers.tex}
\input{transformer_2.tex}
\input{attention.tex}
\input{transformerCV.tex}
\input{transformer_in_tracking.tex}
\input{swinTransformer.tex}
\section{خلاصة}
نستنتج من خلال الدراسة المرجعية بأن الاتجاه في تطوير نظم الملاحقة السائد يعتمد على التعلم العميق وخاصة نماذج المحول
ومن نتائج الشكل 
\ref{fig:comapre}
نلاحظ بأن خوارزميات الملاحقة ماتزال بحاجة إلى مزيد من البحث والتحسين من ناحية السرعة والأداء.
\section{خاتمة}
عرضنا في هذا الفصل مقدمة عن الملاحقة وأنواعها والمشكلات التي تواجها، وكان التركيز على أنواع ملاحقات التعلم العميق، إذ أن البحث يستهدف ملاحق 
\textLR{SwinTrack-Tiny\cite{swinTrack}}
الذي يعتمد على محول
\textLR{Swin\cite{swintransformer}}
لاستخلاص السمات، إذ أن تصميم هذه النسخة من المحول مناسب لتطبيقات الرؤية الصنعية كالملاحقة بسبب سرعة أدائه.
\\
تحدثناعن نموذج المحول وكيفية تطوره باستخدامه لتوابع الانتباه فقط وبذلك تجنب مشاكل الشبكات العودية، وقد تم شرح بنية المحول الأصلي مع التركيز على شرح تابع الانتباه، والذي استخدمناه لدمج سمات الصور في نموذجنا كما سنتحدث في الفصل القادم. وذكرنا تطبيقات المحول في الرؤية الحاسوبية، مع شرح مفصل لنموذج
\textLR{SwinTransformer}
وبينّا سبب استخدامنا له كونه مناسب لتطبيقات الرؤية الصنعية، إذ أنه أقل تعقيداً من نموذج المحول الأصلي في حال صورة دخل بأبعاد كبيرة.
وفي الفقرة الأخيرة تحدثنا عن تطبيقات المحول في  الملاحقة والتي بدأت منذ $2021$ .










